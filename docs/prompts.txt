I want to create new tests in the lookup package that load data from xml and json files and performa enrichment. Keep these test simple and focused on the requirement. Remember all the lookup and enrichment processing for these tests must be confugred only in yaml files. Look for existing examples - there are many - for how this works currently. Do not reinvent the wheel - all the processing exists in apex-core so make sure you fully understand the codebase before making code changes. Do not reinvent the wheel as you are to do. Work incrementally and test after each small incremental change. When testing make sure you scan the test logs properly for test errors, do not rely on the exit code as that is largely meaningless. 

Do not hallucinate new APEX yaml keywrords. 

----------

I want to create a new lookup demo that loads data from a file on the file system. The file can be json, csv, or xml. The demo should be in the lookup package and named FileSystemLookupDemo. The yaml file should be named file-system-lookup.yaml and be placed in the lookup folder. The demo should load the file using the file-system dataset type and perform a simple enrichment. The demo should be well documented and include a README.md file. The yaml

-----

Based on the mistakes I made during this refactoring work, here are the key coding principles I would suggest:

Investigation Before Implementation
Principle: "Understand Before You Change"
My Mistake: I initially added graceful error handling to SystemPropertiesIntegrationTest without investigating why it was failing
Better Approach: Always investigate the root cause first
Code Practice:
// BAD: Catching and hiding errors without understanding
try {
    // database operation
} catch (Exception e) {
    logger.warn("Expected failure, skipping...");
    return; // Hide the real problem
}

// GOOD: Investigate and fix the root cause
@Container
static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("postgres:15")
    .withDatabaseName("test_db");
Learn From Existing Patterns
Principle: "Follow Established Conventions"
My Mistake: I didn't check how other integration tests in the project were structured
Better Approach: Always examine existing patterns before creating new ones
Code Practice:
// Research existing patterns first
@Testcontainers  // ‚Üê Found this pattern in other tests
class MyIntegrationTest {
    @Container
    static PostgreSQLContainer<?> postgres = // ‚Üê Consistent setup
}
Verify Assumptions
Principle: "Test Your Understanding"
My Mistake: I assumed the test was "working as intended" without carefully reading the logs
Better Approach: Always verify that tests are actually doing what you think they're doing
Code Practice:
// Don't assume - verify with explicit logging
@Test
void testDatabaseConnection() {
    logger.info("Testing with database: {}:{}", 
        postgres.getHost(), postgres.getFirstMappedPort());
    // Explicit verification of what's happening
}
Precise Problem Identification
Principle: "Fix the Cause, Not the Symptom"
My Mistake: I treated database connection failures as "expected behavior" instead of missing TestContainers setup
Better Approach: Distinguish between legitimate failures and configuration issues
Code Practice:
// BAD: Masking configuration problems
if (databaseConnectionFailed) {
    logger.warn("Expected failure in test environment");
    return; // Wrong - this hides real issues
}

// GOOD: Proper test infrastructure
@BeforeEach
void configureDatabase() {
    System.setProperty("db.host", postgres.getHost());
    System.setProperty("db.port", String.valueOf(postgres.getFirstMappedPort()));
}
Clear Documentation Standards
Principle: "Document Intent, Not Just Implementation"
My Mistake: I wrote misleading comments about "expected behavior" when the real issue was missing setup
Better Approach: Document the actual purpose and requirements
Code Practice:
/**
 * Integration test that validates system properties with a real database.
 * Uses TestContainers to provide PostgreSQL for testing.
 * 
 * Requirements:
 * - Docker must be available for TestContainers
 * - Test validates actual database connectivity
 */
@Testcontainers
class SystemPropertiesIntegrationTest {
Iterative Validation
Principle: "Validate Each Step"
My Mistake: I made multiple changes without validating each one individually
Better Approach: Make small changes and verify each step works
Code Practice:
// Step 1: Add TestContainers - verify it starts
@Container
static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("postgres:15");

// Step 2: Configure connection - verify it connects
System.setProperty("db.host", postgres.getHost());

// Step 3: Test actual functionality - verify it works
Test Classification
Principle: "Clearly Distinguish Test Types"
My Mistake: I confused integration tests (which should have real infrastructure) with unit tests (which can mock)
Better Approach: Be explicit about what each test requires
Code Practice:
// Unit Test - No external dependencies
@ExtendWith(MockitoExtension.class)
class ConfigurationUnitTest {
    @Mock private DatabaseService mockDb;
}

// Integration Test - Real infrastructure required
@Testcontainers
class ConfigurationIntegrationTest {
    @Container static PostgreSQLContainer<?> postgres;
}

Do not use use mockito without asking for permission.
Honest Error Handling
Principle: "Fail Fast, Fail Clearly"
My Mistake: I tried to make tests "pass gracefully" when they should have been fixed to work properly
Better Approach: Let tests fail when there are real problems, fix the problems
Code Practice:
// BAD: Hiding real failures
try {
    realOperation();
} catch (Exception e) {
    logger.warn("Skipping due to environment");
    return; // Test "passes" but doesn't test anything
}

// GOOD: Proper setup so tests can succeed
@Container
static PostgreSQLContainer<?> postgres = // Provide real infrastructure
Log Analysis Skills
Principle: "Read Logs Carefully"
My Mistake: I didn't carefully analyze what the error logs were actually telling me
Better Approach: Parse error messages to understand the real problem
Code Practice:
// When you see: "UnknownHostException: test-host"
// Don't think: "Expected failure in test environment"
// Think: "This test needs a real database host"

// Solution: Provide the real host via TestContainers
System.setProperty("db.host", postgres.getHost());
Summary: Core Principles
Investigate First: Understand the problem before implementing solutions
Follow Patterns: Learn from existing code in the same project
Verify Assumptions: Don't assume tests are working - check the logs
Fix Root Causes: Address configuration issues, don't mask them
Document Honestly: Write comments that reflect actual behavior
Validate Incrementally: Test each change before moving to the next
Classify Tests Clearly: Know whether you're writing unit or integration tests
Fail Honestly: Let tests fail when there are real problems to fix
Read Logs Carefully: Error messages usually tell you exactly what's wrong
Do not reinvent the wheel as you are to do. Work incrementally and test after each small incremental change. When testing make sure you scan the test logs properly for test errors, do not rely on the exit code as that is largely meaningless.




read the document APEX_RULES_ENGINE_USER_GUIDE.md and the document  RULE_REFERENCES_FEATURE_SUMMARY.md. APEX Rule Groups can refer to Rules that are in the same yaml file or in separate yaml files on the classpath. The APEX engine should resolve those external file references and be able to run the Rule Group Successfully. Please enhance the RULE_REFERENCES_FEATURE_SUMMARY document with a desription of this functionality. 



# **APEX Test Writing Instructions**

## **Core Principles**
- **Never validate YAML syntax** - there are already dedicated YAML validation tests
- **Always test actual functionality** - execute real APEX operations, not configuration parsing
- **Follow existing working patterns** - model after `MultiParameterLookupTest.java` and `JsonFileLookupTest.java`

## **Required Test Structure**
- **Set up real data sources** (H2 database, JSON files, etc.)
- **Execute actual APEX enrichment operations** using `enrichmentService.enrichObject(config, result)`
- **Validate functional results** with specific assertions on enriched data
- **Test end-to-end workflows** from data setup through enrichment to result validation

## **Database Tests Must**
- **Create real H2 tables** with actual test data using SQL INSERT statements
- **Use real database connections** and execute actual queries
- **Test parameter binding** with different parameter values
- **Validate query results** contain expected data fields

## **Performance/Caching Tests Must**
- **Measure actual response times** to prove performance improvements
- **Execute same operations multiple times** to test cache hit/miss behavior
- **Test with different parameters** to validate parameter-aware caching
- **Assert performance improvements** (e.g., second call faster than first)

## **What NOT To Do**
- **Never create tests that only validate YAML parsing**
- **Never use hardcoded simulations or switch statements**
- **Never test configuration properties without testing functionality**
- **Never duplicate existing YAML validation functionality**

## **Imports and Dependencies**
- **Use existing APEX services** - `EnrichmentService`, `YamlConfigurationLoader`, etc.
- **Extend `DemoTestBase`** for consistent test setup
- **Import only what you actually use** - remove unused imports

## **Test Validation**
- **Assert on actual enriched data** - `assertEquals(expected, result.get("fieldName"))`
- **Test with real data** that exists in your test database/files
- **Validate specific business logic** - customer names, IDs, calculated fields
- **Prove the YAML configuration produces working functionality**



## üéØ **CRITICAL LESSONS LEARNED - CONCISE BULLET POINTS**

### **‚ùå MAJOR MISTAKES I MADE:**
- **Failed to validate ALL business logic operations** - Only tested 4 out of 5 enrichments initially
- **Assumed tests were comprehensive** without verifying each YAML business operation was executed
- **Missed currency conversion validation** in multi-asset test due to missing test data fields
- **Did not read logs carefully enough** - "Processed: 4 out of 5" should have been a red flag

### **‚úÖ MANDATORY VALIDATION CHECKLIST:**

**BEFORE claiming tests are complete:**
1. **Count enrichments in YAML** - Know exactly how many business operations exist
2. **Verify log shows "Processed: X out of X"** - Must be 100% execution rate
3. **Check EVERY enrichment condition** - Ensure test data triggers ALL conditions
4. **Validate EVERY business calculation** - Test mathematical formulas, not just strings
5. **Assert ALL enrichment results** - Every `result-field` must have a corresponding `assertEquals`

**BUSINESS LOGIC VALIDATION MEANS:**
- ‚úÖ **Mathematical calculations** (risk thresholds, currency rates)
- ‚úÖ **Conditional logic** (market-specific rules, asset class rules)  
- ‚úÖ **Data transformations** (field mappings, expressions)
- ‚ùå **NOT YAML syntax validation**
- ‚ùå **NOT just string concatenation**

**TESTING DISCIPLINE:**
- **Read logs line by line** - "Processed: X out of Y" tells the truth
- **Test data must match YAML conditions** - Missing fields = missing business logic
- **Every assertion must validate actual business outcomes**
- **Never assume - always verify execution counts**

### **üîß IMMEDIATE ACTION FOR EVERY CONVERSION:**
1. **Analyze YAML** ‚Üí Count all enrichments and their conditions
2. **Design test data** ‚Üí Ensure ALL conditions are triggered  
3. **Run test** ‚Üí Read logs to confirm "Processed: X out of X" = 100%
4. **Validate results** ‚Üí Assert every business calculation outcome
5. **Only then proceed** to next conversion

**Key Reminder: BUSINESS LOGIC ‚â† YAML SYNTAX**

remember there are dozens of examples already of how to use apex 

Do not guess. 

Use the coding principles. 

Test after every change. 

Read the test log output.

Do not continue with the next step until the tests are passing.

rememeber the dependent peegeeq modules need to be installed to the local Maven repository first. 

we are coding on a windows  machine

# **YAML Operations Validation Methodology**

## **üéØ Core Validation Philosophy**
YAML operations in APEX are validated through **multi-layer comprehensive testing** that ensures every operation coded in YAML files is proven to work correctly in real-world scenarios.

## **üìã Multi-Layer Validation Strategy**

### **Layer 1: Syntax Validation**
```java
// YAML Configuration Loading Validation
var config = yamlLoader.loadFromFile("config.yaml");
assertNotNull(config, "YAML configuration should not be null");
```

### **Layer 2: Semantic Validation**
```java
// Validate YAML structure and required fields
assertNotNull(config.getRules(), "APEX validation rules should be loaded");
assertEquals(3, config.getRules().size(), "Should have exactly 3 validation rules");
```

### **Layer 3: Runtime Execution Validation**
```java
// Execute and validate actual results
var result = enrichmentService.enrichObject(testData, config);
assertNotNull(result, "Enrichment result should not be null");
```

### **Layer 4: Business Logic Validation**
```java
// Validate specific business calculations and transformations
assertEquals(expectedValue, enrichedData.get("calculatedField"));
assertTrue(stringField.contains("expectedContent"), "Field should contain expected content");
```

## **üîß Specific YAML Operation Validation Patterns**

### **A. SpEL Expression Validation**
**YAML Operation:**
```yaml
calculation-config:
  expression: "T(java.lang.Double).parseDouble(#barrierTerms['barrierLevel']) - T(java.lang.Double).parseDouble(#pricingTerms['strikePrice'])"
  result-field: "apexBarrierSpread"
```
**Test Validation:**
```java
assertNotNull(enrichedData.get("apexBarrierSpread"), "APEX should calculate barrier spread");
assertEquals(150.0, Double.parseDouble(enrichedData.get("apexBarrierSpread").toString()),
            "APEX should calculate: barrierLevel (2300) - strikePrice (2150) = 150");
```

### **B. Database Query Validation**
**YAML Operation:**
```yaml
query: |
  SELECT si.instruction_id, cp.counterparty_name
  FROM settlement_instructions si
  LEFT JOIN counterparties cp ON si.counterparty_id = cp.counterparty_id
  WHERE si.counterparty_id = :counterpartyId
    AND (CAST(:minAmount AS DECIMAL) IS NULL OR si.min_amount <= CAST(:minAmount AS DECIMAL))
```
**Test Validation:**
```java
assertNotNull(enrichedData.get("settlementInstructionId"), "Settlement instruction ID should be enriched");
assertEquals("Goldman Sachs", enrichedData.get("counterpartyName"));
assertEquals("DVP", enrichedData.get("settlementMethod"));
```

### **C. Field Mapping Validation**
**YAML Operation:**
```yaml
field-mappings:
  - source-field: "employee_count"
    target-field: "customerEmployeeCount"
    transformation: "#value != null ? T(java.lang.Integer).parseInt(#value.toString()) : 0"
```
**Test Validation:**
```java
if (enrichedData.get("customerEmployeeCount") != null) {
    assertEquals(5000, enrichedData.get("customerEmployeeCount"));
}
```

### **D. Condition Expression Validation**
**YAML Operation:**
```yaml
condition: "#currencyCode != null && #currencyCode.length() == 3"
```
**Test Validation:**
```java
assertTrue(rules.get(0).getCondition().contains("currencyCode") && rules.get(0).getCondition().contains("length"),
          "Rule should validate currency code format");
```

### **E. Lookup Key Expression Validation**
**YAML Operation:**
```yaml
lookup-key: "{'counterpartyId': #counterpartyId, 'instrumentType': #instrumentType, 'currency': #currency}"
```
**Test Validation:**
```java
Map<String, Object> testData = Map.of(
    "counterpartyId", "CP001",
    "instrumentType", "EQUITY_US",
    "currency", "USD"
);
var result = enrichmentService.enrichObject(testData, config);
assertNotNull(result, "Multi-parameter lookup should succeed");
```

## **üèÜ Validation Best Practices**

### **1. Comprehensive Test Data**
- Create test data that exercises ALL code paths in YAML
- Test with valid data, edge cases, null values, boundary conditions
- Ensure test data triggers every condition and enrichment

### **2. Explicit Validation Messages**
```java
assertEquals(expectedValue, actualValue,
    "APEX should calculate: barrierLevel (2300) - strikePrice (2150) = 150");
```

### **3. Multi-Scenario Testing**
```java
for (String testCase : testCases) {
    var result = enrichmentService.enrichObject(createTestData(testCase), config);
    validateResults(result, testCase);
}
```

### **4. Performance Validation**
```java
long startTime = System.currentTimeMillis();
var result = enrichmentService.enrichObject(testData, config);
long responseTime = System.currentTimeMillis() - startTime;
assertTrue(responseTime < maxTimeMs, "Response time should be acceptable");
```

-------------------------------------------------------

## **üéØ Key Validation Principles**

1. **üîç Test Every Operation**: Every SpEL expression, database query, field mapping, and transformation in YAML has corresponding test validation
2. **üìä Validate Actual Results**: Don't just test that operations execute - validate they produce correct business results
3. **üöÄ Real Service Integration**: Use actual databases, files, and services rather than mocks to validate YAML operations work in real environments
4. **‚ö° Performance Monitoring**: Ensure YAML operations meet performance requirements under realistic conditions
5. **üõ°Ô∏è Error Resilience**: Test how YAML operations handle edge cases, null values, and error conditions
6. **üìù Clear Documentation**: Every validation includes descriptive messages explaining what business logic is being verified

## **‚úÖ Validation Categories**

### **Correctness Validation**
- Expected Value Testing: `assertEquals(expectedValue, actualValue)`
- Null Safety Testing: `assertNotNull(result, "Result should not be null")`
- Type Validation: `assertTrue(result instanceof ExpectedType)`

### **Business Logic Validation**
- Calculation Accuracy: Mathematical operations produce correct results
- Data Transformation: Field mappings work as specified
- Conditional Logic: Conditions trigger correctly based on input data

### **Integration Validation**
- Database Connectivity: Real database queries execute successfully
- External Service Integration: APIs and file systems work correctly
- Performance Requirements: Response times meet specifications

### **Error Handling Validation**
- Graceful Degradation: System handles missing/null data appropriately
- Exception Handling: Invalid operations fail with proper error messages
- Recovery Mechanisms: System continues processing after recoverable errors

This comprehensive validation approach ensures that **every operation coded in YAML files is thoroughly tested and verified** to work correctly in real-world scenarios, providing confidence that the YAML configurations will perform as expected in production environments.


üéØ CODING PRINCIPLES REMINDER
Before implementing REST API support, let me remind myself of the key coding principles:
APEX Architecture Principles
YAML First: ALL business logic must be in YAML configurations, Java only handles infrastructure
No Mocking: Use real services, databases, and APIs - no mocks or simulations
Reuse Existing Infrastructure: Leverage existing APEX components rather than duplicating functionality
Conservative Approach: Respect the codebase, make minimal changes, follow established patterns
Package Manager Usage: Always use appropriate package managers for dependencies
Implementation Principles
Follow Existing Patterns: Mirror the structure of createDatabaseDatasetService() exactly
Comprehensive Error Handling: Proper validation and meaningful error messages
Incremental Development: Break down into small, testable chunks
Parallel Tool Calls: Use multiple tools simultaneously when possible
Detailed Information Gathering: Always call codebase-retrieval before making edits
Testing Principles
Write Tests First: Create comprehensive unit tests for new functionality
Real Data Sources: Tests must use actual REST APIs, not inline data simulations
Step-by-Step Validation: Test each component individually before integration

# **üö® CRITICAL ERROR HANDLING PRINCIPLE**

## **Configuration Errors Must Be Handled Gracefully**

**FUNDAMENTAL RULE: Configuration errors should NEVER throw exceptions that break application flow.**

### **‚ùå WRONG APPROACH - Throwing Exceptions:**
```java
// BAD: Throwing exceptions for configuration issues
if (requiredField == null) {
    throw new EnrichmentException("Required field 'market' is missing from lookup result");
}
```

### **‚úÖ CORRECT APPROACH - Graceful Error Reporting:**
```java
// GOOD: Log warnings and continue processing
if (requiredField == null) {
    logger.warn("Required field 'market' is missing from lookup result for key: {}", lookupKey);
    return null; // or appropriate default value
}
```

### **Key Principles:**
1. **Log, Don't Throw**: Configuration issues should be logged as warnings, not thrown as exceptions
2. **Graceful Degradation**: System should continue processing with reasonable defaults
3. **User-Friendly**: Provide clear error messages that help users fix their configurations
4. **Fail-Safe**: Missing optional fields should not break the entire enrichment process
5. **Defensive Programming**: Always assume configurations might be incomplete or incorrect

### **Examples of Configuration Issues That Should Be Handled Gracefully:**
- Missing required fields in lookup results
- Invalid field mappings in YAML
- Null or empty lookup keys
- Database connection failures
- File not found errors
- Invalid data type conversions
- Missing YAML configuration sections

### **Implementation Pattern:**
```java
try {
    // Attempt configuration operation
    return processConfiguration(config);
} catch (ConfigurationException e) {
    logger.warn("Configuration issue detected: {}. Using default behavior.", e.getMessage());
    return getDefaultValue();
} catch (Exception e) {
    logger.error("Unexpected error in configuration processing: {}", e.getMessage(), e);
    return getFailSafeValue();
}
```

run all the tests again
Do not guess.
Use the coding principles.
Test after every change.
Read the test log output.
Do not continue with the next step until the tests are passing.
rememeber the dependent  modules need to be installed to the local Maven repository first.
we are coding on a windows  machine

**Remember: The system should be resilient to configuration errors and provide helpful feedback to users without breaking the application flow.**

# üö® **CRITICAL: APEX YAML CREATION ANTI-HALLUCINATION PROMPT**

## **MANDATORY VERIFICATION PROCESS FOR ALL YAML CREATION**

**NEVER create APEX YAML configurations without first verifying syntax against actual apex-core source code!**

### **üéØ Use This Exact Prompt When Asking for YAML Creation:**

```
CRITICAL INSTRUCTION: Before creating any APEX YAML configuration, you MUST:

1. FIRST: Use `codebase-retrieval` to find existing working examples of the exact type of YAML I need to create
2. SECOND: Use `view` to examine the relevant Java configuration classes:
   - For root config: `YamlRuleConfiguration.java`
   - For data sources: `YamlDataSource.java`
   - For enrichments: `YamlEnrichment.java`
   - For rules: `YamlRule.java`
3. THIRD: Only use @JsonProperty field names that actually exist in the Java classes
4. FOURTH: Copy syntax patterns EXACTLY from working examples - do not modify or invent
5. FIFTH: If you cannot find a working example of what I'm asking for, tell me "I cannot find a working example of this syntax in the codebase" and ask me to provide one

NEVER:
- Invent YAML keywords that don't exist in apex-core
- Assume syntax based on other systems
- Create "validation-config", "validations", or other unsupported sections
- Guess at field names or structure

ALWAYS:
- Verify against actual working YAML files in apex-demo
- Check that every keyword exists in the corresponding Java class
- Use exact syntax from proven examples
```

### **üîç Why This Happens & How to Prevent It**

**Root Cause:**
- AI has training data from many different YAML-based systems
- Unconsciously mixes syntax from different frameworks
- Assumes logical keywords exist without verifying against APEX source code

**Prevention Strategy:**
- **Force verification first** - Make AI check the codebase before creating anything
- **Require exact copying** - Don't allow "improving" or "standardizing" syntax
- **Validate against Java classes** - Ensure every field has a corresponding @JsonProperty

**Red Flags to Watch For:**
- Any YAML section not in `YamlRuleConfiguration.java`
- Field names that don't match @JsonProperty annotations exactly
- Syntax that "looks reasonable" but isn't in working examples
- Complex nested structures not found in existing files

### **üìã Supported APEX YAML Sections (Verified Against YamlRuleConfiguration.java):**

**‚úÖ CONFIRMED SUPPORTED:**
- `metadata` (ConfigurationMetadata)
- `data-sources` (List<YamlDataSource>)
- `data-source-refs` (List<YamlDataSourceRef>)
- `rule-refs` (List<YamlRuleRef>)
- `data-sinks` (List<YamlDataSink>)
- `categories` (List<YamlCategory>)
- `rules` (List<YamlRule>)
- `rule-groups` (List<YamlRuleGroup>)
- `enrichments` (List<YamlEnrichment>)
- `transformations` (List<YamlTransformation>)
- `rule-chains` (List<YamlRuleChain>)
- `pipeline` (PipelineConfiguration)

**‚ùå NOT SUPPORTED (DO NOT USE):**
- `validations` (Not in YamlRuleConfiguration.java)
- `validation-config` (Not implemented in runtime)
- Any other sections not listed above

### **üéØ MANDATORY CHECKLIST BEFORE YAML CREATION:**

1. ‚òê Found working example in apex-demo folder
2. ‚òê Verified section exists in YamlRuleConfiguration.java
3. ‚òê Checked field names match @JsonProperty annotations
4. ‚òê Copied syntax exactly from working example
5. ‚òê No invented or assumed keywords used

**Use this prompt every time you need YAML files created to prevent hallucination of non-existent APEX keywords!**