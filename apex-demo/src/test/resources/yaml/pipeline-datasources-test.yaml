metadata:
  id: "pipeline-datasources-test"
  name: "Pipeline Data Sources Test"
  version: "1.0.0"
  description: "Test pipeline document with comprehensive data sources configuration"
  type: "pipeline"
  author: "apex-test-suite@example.com"
  created-date: "2025-09-14"
  tags: ["apex-test", "pipeline", "data-sources"]

# Pipeline orchestration
pipeline:
  name: "multi-source-data-pipeline"
  description: "Pipeline processing data from multiple input sources"

  steps:
    - name: "extract-csv-data"
      type: "extract"
      source: "customer-csv-source"
      operation: "getAllRecords"
      description: "Extract data from CSV file"

    - name: "extract-database-data"
      type: "extract"
      source: "reference-database-source"
      operation: "getAllReferenceData"
      description: "Extract reference data from database"

    - name: "extract-api-data"
      type: "extract"
      source: "external-api-source"
      operation: "getExternalData"
      description: "Extract data from external API"

    - name: "merge-data"
      type: "transform"
      description: "Merge data from multiple sources"
      depends-on: ["extract-csv-data", "extract-database-data", "extract-api-data"]

    - name: "load-merged-data"
      type: "load"
      sink: "output-database"
      operation: "insertMergedRecord"
      description: "Load merged data to output database"
      depends-on: ["merge-data"]

# Input data sources - comprehensive configuration
data-sources:
  - name: "customer-csv-source"
    type: "file-system"
    enabled: true
    description: "Customer data from CSV files"
    
    connection:
      basePath: "./data/customers"
      filePattern: "customer-*.csv"
      recursive: true
      
    fileFormat:
      type: "csv"
      hasHeaderRow: true
      delimiter: ","
      quoteChar: "\""
      escapeChar: "\\"
      encoding: "UTF-8"
      
    queries:
      getAllRecords: "SELECT * FROM csv"
      getActiveCustomers: "SELECT * FROM csv WHERE status = 'ACTIVE'"
      
    cache:
      enabled: true
      ttlSeconds: 3600
      maxSize: 10000

  - name: "reference-database-source"
    type: "database"
    sourceType: "postgresql"
    enabled: true
    description: "Reference data from PostgreSQL database"
    
    connection:
      host: "localhost"
      port: 5432
      database: "reference_data"
      username: "readonly_user"
      password: "${REF_DB_PASSWORD}"
      
    queries:
      getAllReferenceData: "SELECT * FROM reference_tables ORDER BY table_name"
      getCurrencyRates: "SELECT * FROM currency_rates WHERE effective_date = CURRENT_DATE"
      getCountryCodes: "SELECT * FROM country_codes WHERE active = true"
      
    cache:
      enabled: true
      ttlSeconds: 7200
      maxSize: 5000
      
    healthCheck:
      enabled: true
      query: "SELECT 1"
      intervalSeconds: 60

  - name: "external-api-source"
    type: "rest-api"
    enabled: true
    description: "External market data API"
    
    connection:
      baseUrl: "https://api.marketdata.com/v1"
      timeout: 10000
      maxConnections: 5
      
    authentication:
      type: "api-key"
      keyHeader: "X-API-Key"
      keyValue: "${MARKET_API_KEY}"
      
    endpoints:
      getExternalData: "/market-data/latest"
      getHistoricalData: "/market-data/historical/{date}"
      getInstrumentData: "/instruments/{symbol}"
      
    cache:
      enabled: true
      ttlSeconds: 300
      maxSize: 1000
      
    circuitBreaker:
      enabled: true
      failureThreshold: 5
      recoveryTimeoutMs: 30000

  - name: "json-file-source"
    type: "file-system"
    enabled: true
    description: "Configuration data from JSON files"
    
    connection:
      basePath: "./data/config"
      filePattern: "config-*.json"
      
    fileFormat:
      type: "json"
      rootPath: "$.data"
      
    queries:
      getAllConfigs: "$[*]"
      getConfigByType: "$[?(@.type == '{configType}')]"

# Output data sinks
data-sinks:
  - name: "output-database"
    type: "database"
    sourceType: "h2"
    enabled: true
    description: "Output database for merged data"
    
    connection:
      database: "./output/merged_data"
      username: "sa"
      password: ""
      
    operations:
      insertMergedRecord: |
        INSERT INTO merged_data (source_type, record_id, data_json, processed_at) 
        VALUES (:source_type, :record_id, :data_json, CURRENT_TIMESTAMP)
